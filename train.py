import os
import pickle
import pandas as pd

# ThÆ° viá»‡n cho Content-Based
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ThÆ° viá»‡n cho Collaborative Filtering
from surprise import SVD, Dataset, Reader
from surprise.dump import dump
from surprise.model_selection import cross_validate

# --- 1. Cáº¤U HÃŒNH ---
# ÄÆ°á»ng dáº«n tá»›i cÃ¡c file dá»¯ liá»‡u vÃ  nÆ¡i lÆ°u cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ train
DATA_DIR = "dataset"
ARTIFACTS_DIR = "artifacts"  # ThÆ° má»¥c Ä‘á»ƒ lÆ°u cÃ¡c "sáº£n pháº©m" cá»§a mÃ´ hÃ¬nh

# ÄÆ°á»ng dáº«n file input
MOVIES_PATH = os.path.join(DATA_DIR, "movies.csv")
RATINGS_PATH = os.path.join(DATA_DIR, "ratings.csv")

# ÄÆ°á»ng dáº«n file output
# LÆ°u ma tráº­n tÆ°Æ¡ng Ä‘á»“ng cá»§a Content-Based model
COSINE_SIM_PATH = os.path.join(ARTIFACTS_DIR, "cosine_similarity.pkl")
# LÆ°u dataframe movies Ä‘Ã£ xá»­ lÃ½ Ä‘á»ƒ tra cá»©u
MOVIES_DF_PATH = os.path.join(ARTIFACTS_DIR, "movies_df.pkl")
# LÆ°u Collaborative Filtering model
CF_MODEL_PATH = os.path.join(ARTIFACTS_DIR, "svd_model.pkl")


def train_content_based():
    """
    Huáº¥n luyá»‡n mÃ´ hÃ¬nh Content-Based Filtering.
    - Äá»c file movies.csv
    - Xá»­ lÃ½ cá»™t 'genres'
    - TÃ­nh toÃ¡n ma tráº­n TF-IDF
    - TÃ­nh toÃ¡n ma tráº­n tÆ°Æ¡ng Ä‘á»“ng Cosine
    - LÆ°u ma tráº­n vÃ  dataframe movies vÃ o file .pkl
    """
    print("--- ğŸš€ Báº¯t Ä‘áº§u training Content-Based model ---")

    # Äá»c vÃ  xá»­ lÃ½ dá»¯ liá»‡u
    df_movies = pd.read_csv(MOVIES_PATH, encoding="latin-1", sep="\t", usecols=["movie_id", "title", "genres"])
    # Xá»­ lÃ½ cá»™t genres Ä‘á»ƒ phÃ¹ há»£p cho TF-IDF
    df_movies['genres_processed'] = df_movies['genres'].str.replace('|', ' ', regex=False).str.replace('-', '', regex=False)

    # Khá»Ÿi táº¡o vÃ  fit TfidfVectorizer
    tfidf = TfidfVectorizer(stop_words='english')
    tfidf_matrix = tfidf.fit_transform(df_movies['genres_processed'])

    # TÃ­nh ma tráº­n tÆ°Æ¡ng Ä‘á»“ng cosine
    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # Táº¡o DataFrame tá»« ma tráº­n tÆ°Æ¡ng Ä‘á»“ng Ä‘á»ƒ dá»… tra cá»©u báº±ng title
    cosine_sim_df = pd.DataFrame(cosine_sim, index=df_movies['title'], columns=df_movies['title'])

    # LÆ°u cÃ¡c "sáº£n pháº©m" ra file
    print(f"LÆ°u ma tráº­n tÆ°Æ¡ng Ä‘á»“ng vÃ o: {COSINE_SIM_PATH}")
    with open(COSINE_SIM_PATH, 'wb') as f:
        pickle.dump(cosine_sim_df, f)

    print(f"LÆ°u dataframe movies vÃ o: {MOVIES_DF_PATH}")
    with open(MOVIES_DF_PATH, 'wb') as f:
        pickle.dump(df_movies, f)

    print("--- âœ… Training Content-Based hoÃ n táº¥t. ---")


def train_collaborative_filtering():
    """
    Huáº¥n luyá»‡n mÃ´ hÃ¬nh Collaborative Filtering báº±ng thÆ° viá»‡n Surprise.
    - Äá»c file ratings.csv
    - Load dá»¯ liá»‡u vÃ o Dataset cá»§a Surprise
    - Huáº¥n luyá»‡n thuáº­t toÃ¡n SVD
    - LÆ°u model Ä‘Ã£ huáº¥n luyá»‡n ra file
    """
    print("\n--- ğŸš€ Báº¯t Ä‘áº§u training Collaborative Filtering model ---")

    # Äá»c dá»¯ liá»‡u ratings
    df_ratings = pd.read_csv(RATINGS_PATH, encoding="latin-1", sep="\t", usecols=["user_id", "movie_id", "rating"])

    # Surprise yÃªu cáº§u má»™t Ä‘á»‹nh dáº¡ng reader riÃªng
    reader = Reader(rating_scale=(1, 5))  # Thang Ä‘iá»ƒm rating tá»« 1 Ä‘áº¿n 5

    # Load dataframe vÃ o dataset cá»§a Surprise
    data = Dataset.load_from_df(df_ratings[['user_id', 'movie_id', 'rating']], reader)

    # XÃ¢y dá»±ng trainset tá»« toÃ n bá»™ dá»¯ liá»‡u
    trainset = data.build_full_trainset()

    # Sá»­ dá»¥ng thuáº­t toÃ¡n SVD (má»™t trong nhá»¯ng thuáº­t toÃ¡n phá»• biáº¿n nháº¥t)
    algo = SVD(n_factors=100, n_epochs=20, random_state=42, verbose=True)

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    print("Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh SVD...")
    algo.fit(trainset)

    # LÆ°u model Ä‘Ã£ huáº¥n luyá»‡n
    # Surprise cÃ³ hÃ m dump riÃªng Ä‘á»ƒ tá»‘i Æ°u viá»‡c lÆ°u model
    print(f"LÆ°u model SVD vÃ o: {CF_MODEL_PATH}")
    dump(file_name=CF_MODEL_PATH, algo=algo)

    print("--- âœ… Training Collaborative Filtering hoÃ n táº¥t. ---")

    print("=" * 50)

    print("\n--- ğŸ“Š Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh SVD ---")
    # Cháº¡y cross-validation vá»›i 5-folds
    cv_results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

    # Láº¥y káº¿t quáº£ trung bÃ¬nh
    mean_rmse = cv_results['test_rmse'].mean()
    mean_mae = cv_results['test_mae'].mean()

    print(f"\nKáº¿t quáº£ Ä‘Ã¡nh giÃ¡ trung bÃ¬nh:")
    print(f"RMSE: {mean_rmse:.4f}")
    print(f"MAE:  {mean_mae:.4f}")


if __name__ == "__main__":
    print("Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh training...")

    # Táº¡o thÆ° má»¥c 'artifacts' náº¿u chÆ°a tá»“n táº¡i
    if not os.path.exists(ARTIFACTS_DIR):
        print(f"Táº¡o thÆ° má»¥c {ARTIFACTS_DIR} Ä‘á»ƒ lÆ°u model...")
        os.makedirs(ARTIFACTS_DIR)

    # Cháº¡y training cho cáº£ hai mÃ´ hÃ¬nh
    train_content_based()
    train_collaborative_filtering()

    print("\nğŸ‰ ToÃ n bá»™ quÃ¡ trÃ¬nh training Ä‘Ã£ hoÃ n táº¥t thÃ nh cÃ´ng!")
    print(f"CÃ¡c file model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c '{ARTIFACTS_DIR}'.")

    print("=" * 50)

